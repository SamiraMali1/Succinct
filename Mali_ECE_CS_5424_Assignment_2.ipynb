{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mali_ECE_CS_5424_Assignment_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamiraMali1/Succinct/blob/master/Mali_ECE_CS_5424_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh6N3SPWUSMB"
      },
      "source": [
        "# ECE-5424 / CS-5824 Advanced Machine Learning\n",
        "# Assignment 2: Coding [60 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIA3Hv8kUSMZ"
      },
      "source": [
        "In this assignment, you need to complete the following two sections:\n",
        "1. Logistic regression\n",
        "2. Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yxhzck1aWX7q"
      },
      "source": [
        "## Submission guideline\n",
        "\n",
        "1. Click the Save button at the top of the Jupyter Notebook.\n",
        "2. Please make sure to have entered your Virginia Tech PID below.\n",
        "3. Select Edit -> Clear All Output. This will clear all the outputs from all cells (but will keep the content of the cells).\n",
        "4. Select Runtime -> Restart and Run All. This will run all the cells in order.\n",
        "5. Once you've rerun everything, select File -> Print -> Save as PDF, or you can use the provided code at the end of this notebook.\n",
        "6. Look at the PDF file and make sure all your solutions are there, displayed correctly. \n",
        "7. Upload the PDF file and this notebook **INDEPENDENTLY**.\n",
        "8. Please **DO NOT** upload any data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4K3x2x_USMd"
      },
      "source": [
        "### Please Write Your VT PID Here: \r\n",
        "\r\n",
        "smali\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7vN9PE-ZFvg"
      },
      "source": [
        "# Section 0. Environment Set Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Pja5zjFXwTp"
      },
      "source": [
        "Mount your google drive in google colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdVPU9EUXvij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcc60c93-572f-4f39-ae68-a24d352500f5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg6RLG8AX73v"
      },
      "source": [
        "Append the directory to your python path using sys.\n",
        "\n",
        "**Please do modify the `customized_path_to_your_homework` to where you uploaded your homework in the Google Drive**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwSblWSIX-qM"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import math\n",
        "\n",
        "# modify \"customized_path_to_your_homework\" here to where you uploaded your homework\n",
        "customized_path_to_your_homework = '/content/gdrive/MyDrive/Colab Notebooks/HW2'\n",
        "sys.path.append(customized_path_to_your_homework)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXkxh1F0USP7"
      },
      "source": [
        "# Section 1. Logistic Regression [30 pts]:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nchNW0zXUSP7"
      },
      "source": [
        "The following logistic regression assignment is modified from [Stanford CS229](http://cs229.stanford.edu//). Please complete and hand in this completed worksheet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYOvYZ_4USP8"
      },
      "source": [
        "## Logistic Regression\n",
        "In this section, you need to implement logsitic regression to solve a binary classification problem. Let's first get our data ready:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3m-u3V1Xi6t"
      },
      "source": [
        "import os\n",
        "logistic_x_data_path = os.path.join(customized_path_to_your_homework, 'data/logistic_x_.txt')\n",
        "logistic_y_data_path = os.path.join(customized_path_to_your_homework, 'data/logistic_y_.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op9aacdfWjBH"
      },
      "source": [
        "def feature_normalize(X):\n",
        "    \n",
        "    # feature_normalize: Normalizes the features in X \n",
        "    # feature_normalize(X): returns a normalized version of X where the mean value of each feature is 0 and the standard deviation is 1. \n",
        "    # This is often a good preprocessing step to do when working with learning algorithms.\n",
        "    \n",
        "    mu     = 0\n",
        "    sigma  = 0\n",
        "    mu     = np.mean(X, 0)\n",
        "    sigma  = np.std(X, 0)\n",
        "    X      = (X - mu) / sigma\n",
        "    X_norm = X\n",
        "  \n",
        "    return X_norm, mu, sigma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJJmpMWsUSP9"
      },
      "source": [
        "import numpy as np\n",
        "# Only use the first 70 samples for training (and validation),\n",
        "# and treat the rest of them as hold-out testing set.\n",
        "X = np.loadtxt(logistic_x_data_path) \n",
        "y = np.loadtxt(logistic_y_data_path).reshape(-1, 1) \n",
        "\n",
        "X, mu, std = feature_normalize(X)\n",
        "\n",
        "# Add a column of ones to X for the bias weight.\n",
        "m = len(X)\n",
        "X = np.concatenate((np.ones((m, 1)), X), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcrnuQikUSQE"
      },
      "source": [
        "Here, the input $x^{(i)}\\in\\mathbb{R^2}$ and $y^{(i)}\\in\\{-1, 1\\}$. Like we have mentioned, it is better to visualize the data first before you start working on it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWu_JnqjUSQF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "761afa34-ca66-4c72-ef05-154c148d25c5"
      },
      "source": [
        "# Plot the feature according to their class label.\n",
        "# Note that we exclude column 0, which is the colunm we padded with one in the previous block.\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(X[np.where(y==1), 1], X[np.where(y==1), 2], 'rx')\n",
        "plt.plot(X[np.where(y==-1), 1], X[np.where(y==-1), 2], 'bo')  \n",
        "plt.xlabel('x2')\n",
        "plt.ylabel('x1')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubw2Ad2MUSQM"
      },
      "source": [
        "In the following, you need to implement logistic regression. Recall that when $y^{(i)}\\in{-1,1}$, the objective function for binary logistic regression can be expressed as:\n",
        "\\begin{equation*}\n",
        "J(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}\\log{\\left(1+e^{-y^{(i)}\\theta^Tx^{(i)}}\\right)}=-\\frac{1}{m}\\sum_{i=1}^m\\log{\\left(h_{\\theta}(y^{(i)}x^{(i)})\\right)}\n",
        "\\end{equation*}\n",
        "where the hypothesis is the **sigmoid function**: \n",
        "\\begin{equation*}\n",
        "h_\\theta(y^{(i)}x^{(i)})=\\frac{1}{1+e^{-y^{(i)}\\theta^{T}x^{(i)}}}\n",
        "\\end{equation*}\n",
        "which we have seen in class (and assignment 0). Similar to the previous section, we can minimize the objective function $J(\\theta)$ using  batch gradient descent:\n",
        "\\begin{equation*}\n",
        "\\theta_j := \\theta_j - \\alpha \\frac{1}{m}\\sum_{i=1}^{m}h_\\theta(-y^{(i)}x^{(i)})(-y^{(i)}x_j^{(i)})\n",
        "\\end{equation*}\n",
        "\n",
        "Now, your task is to complete the function `sigmoid`, `compute_cost`, `compute_gradient`, and `gradient_descent__logistic` for logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqd3w1jYUSQO"
      },
      "source": [
        "def sigmoid(z):\n",
        "    #####################################################################\n",
        "    # Instructions: Implement sigmoid function g                        #\n",
        "    #####################################################################\n",
        "    #z=np.dot(y,theta.T,X)\n",
        "    g = 1 / (1 + np.exp(-z))\n",
        "    pass\n",
        "    #####################################################################\n",
        "    #                       END OF YOUR CODE                            #\n",
        "    #####################################################################\n",
        "    return g\n",
        "\n",
        "def compute_cost(X, y, theta):\n",
        "    \n",
        "    # You need to return the following variables correctly \n",
        "    J = 0;\n",
        "    #####################################################################\n",
        "    # Instructions: Implement the objective function J(theta)           #\n",
        "    #####################################################################\n",
        "    pass\n",
        "    h = sigmoid(np.dot(X,theta))\n",
        "    cost = (-y * np.log(h)) - ((1-y)*np.log(1-h))\n",
        "    J = 1/m * sum(cost)  \n",
        "    #####################################################################\n",
        "    #                       END OF YOUR CODE                            #\n",
        "    #####################################################################\n",
        "    return J\n",
        "\n",
        "def compute_gradient(X, y, theta):\n",
        "    #####################################################################\n",
        "    # Instructions: Implement gradient function gradient_               #\n",
        "    #####################################################################\n",
        "    pass\n",
        "    h2 = sigmoid(np.dot(X,theta))\n",
        "    gradient_ = 1/m * (np.dot(X.transpose(), (h2-y)))\n",
        "    #####################################################################\n",
        "    #                       END OF YOUR CODE                            #\n",
        "    #####################################################################\n",
        "    #print (gradient_)\n",
        "    return gradient_\n",
        "\n",
        "\n",
        "def gradient_descent_logistic(X, y, theta, alpha, num_iters):\n",
        "    m = len(y)\n",
        "    J_history = []\n",
        "    for iter in range(num_iters):\n",
        "\n",
        "        #####################################################################\n",
        "        # Instructions: Perform a single gradient step on the parameter     #\n",
        "        #               vector theta using the implemented compute_gradient #\n",
        "        #                                                                   #      \n",
        "        # Hint: While debugging, it can be useful to print out the values   #\n",
        "        #       of the cost function (compute_cost) and gradient here.      # \n",
        "        #####################################################################\n",
        "        grad=compute_gradient(X, y, theta)\n",
        "        theta = theta - alpha* grad\n",
        "        pass\n",
        "        #####################################################################\n",
        "        #                       END OF YOUR CODE                            #\n",
        "        #####################################################################\n",
        "    \n",
        "\n",
        "        # Save the cost J in every iteration \n",
        "        J = compute_cost(X, y, theta)\n",
        "        print(J)\n",
        "        J_history.append(J)\n",
        "    \n",
        "    return theta, J_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbqxwYXNUSQR"
      },
      "source": [
        "Now, fit your model, and see if it is learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lZwfDtsUSQT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b63d633-6363-4b76-e850-0ef289eeb01f"
      },
      "source": [
        "# Train your model.\n",
        "theta = np.zeros((X.shape[1], 1))\n",
        "alpha = 0.1;\n",
        "num_iters = 400;\n",
        "theta, J_history = gradient_descent_logistic(X, y, theta, alpha, num_iters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.60179988]\n",
            "[0.51554018]\n",
            "[0.43401935]\n",
            "[0.356874]\n",
            "[0.28374032]\n",
            "[0.21426487]\n",
            "[0.14811213]\n",
            "[0.08496915]\n",
            "[0.02454792]\n",
            "[-0.03341402]\n",
            "[-0.08915407]\n",
            "[-0.14288585]\n",
            "[-0.19480093]\n",
            "[-0.24507068]\n",
            "[-0.29384822]\n",
            "[-0.34127033]\n",
            "[-0.38745919]\n",
            "[-0.432524]\n",
            "[-0.47656247]\n",
            "[-0.51966214]\n",
            "[-0.56190154]\n",
            "[-0.60335123]\n",
            "[-0.64407471]\n",
            "[-0.68412924]\n",
            "[-0.72356653]\n",
            "[-0.76243337]\n",
            "[-0.80077215]\n",
            "[-0.83862139]\n",
            "[-0.87601608]\n",
            "[-0.91298813]\n",
            "[-0.94956665]\n",
            "[-0.98577823]\n",
            "[-1.02164723]\n",
            "[-1.05719598]\n",
            "[-1.09244498]\n",
            "[-1.12741308]\n",
            "[-1.16211764]\n",
            "[-1.19657466]\n",
            "[-1.23079893]\n",
            "[-1.2648041]\n",
            "[-1.29860282]\n",
            "[-1.3322068]\n",
            "[-1.36562693]\n",
            "[-1.39887329]\n",
            "[-1.43195528]\n",
            "[-1.46488165]\n",
            "[-1.49766053]\n",
            "[-1.53029953]\n",
            "[-1.56280574]\n",
            "[-1.59518579]\n",
            "[-1.62744589]\n",
            "[-1.65959184]\n",
            "[-1.69162909]\n",
            "[-1.72356273]\n",
            "[-1.75539758]\n",
            "[-1.78713811]\n",
            "[-1.81878858]\n",
            "[-1.85035295]\n",
            "[-1.88183499]\n",
            "[-1.91323823]\n",
            "[-1.94456599]\n",
            "[-1.97582144]\n",
            "[-2.00700752]\n",
            "[-2.03812706]\n",
            "[-2.06918271]\n",
            "[-2.10017698]\n",
            "[-2.13111225]\n",
            "[-2.16199077]\n",
            "[-2.19281467]\n",
            "[-2.22358599]\n",
            "[-2.25430665]\n",
            "[-2.28497847]\n",
            "[-2.31560318]\n",
            "[-2.34618245]\n",
            "[-2.37671783]\n",
            "[-2.40721083]\n",
            "[-2.43766286]\n",
            "[-2.46807528]\n",
            "[-2.49844938]\n",
            "[-2.52878639]\n",
            "[-2.5590875]\n",
            "[-2.58935381]\n",
            "[-2.61958641]\n",
            "[-2.64978632]\n",
            "[-2.67995451]\n",
            "[-2.71009193]\n",
            "[-2.74019947]\n",
            "[-2.770278]\n",
            "[-2.80032832]\n",
            "[-2.83035123]\n",
            "[-2.86034749]\n",
            "[-2.89031782]\n",
            "[-2.92026291]\n",
            "[-2.95018343]\n",
            "[-2.98008002]\n",
            "[-3.0099533]\n",
            "[-3.03980386]\n",
            "[-3.06963227]\n",
            "[-3.09943907]\n",
            "[-3.12922479]\n",
            "[-3.15898994]\n",
            "[-3.188735]\n",
            "[-3.21846044]\n",
            "[-3.24816673]\n",
            "[-3.27785429]\n",
            "[-3.30752355]\n",
            "[-3.3371749]\n",
            "[-3.36680876]\n",
            "[-3.39642548]\n",
            "[-3.42602545]\n",
            "[-3.45560901]\n",
            "[-3.48517651]\n",
            "[-3.51472827]\n",
            "[-3.54426461]\n",
            "[-3.57378585]\n",
            "[-3.60329229]\n",
            "[-3.63278421]\n",
            "[-3.66226189]\n",
            "[-3.69172561]\n",
            "[-3.72117564]\n",
            "[-3.75061222]\n",
            "[-3.7800356]\n",
            "[-3.80944603]\n",
            "[-3.83884375]\n",
            "[-3.86822896]\n",
            "[-3.89760191]\n",
            "[-3.9269628]\n",
            "[-3.95631184]\n",
            "[-3.98564922]\n",
            "[-4.01497516]\n",
            "[-4.04428984]\n",
            "[-4.07359345]\n",
            "[-4.10288616]\n",
            "[-4.13216815]\n",
            "[-4.16143961]\n",
            "[-4.19070068]\n",
            "[-4.21995155]\n",
            "[-4.24919236]\n",
            "[-4.27842327]\n",
            "[-4.30764443]\n",
            "[-4.33685599]\n",
            "[-4.36605809]\n",
            "[-4.39525088]\n",
            "[-4.42443449]\n",
            "[-4.45360906]\n",
            "[-4.48277471]\n",
            "[-4.51193158]\n",
            "[-4.54107979]\n",
            "[-4.57021945]\n",
            "[-4.5993507]\n",
            "[-4.62847365]\n",
            "[-4.6575884]\n",
            "[-4.68669508]\n",
            "[-4.7157938]\n",
            "[-4.74488465]\n",
            "[-4.77396775]\n",
            "[-4.80304319]\n",
            "[-4.83211109]\n",
            "[-4.86117153]\n",
            "[-4.89022461]\n",
            "[-4.91927044]\n",
            "[-4.94830909]\n",
            "[-4.97734066]\n",
            "[-5.00636525]\n",
            "[-5.03538294]\n",
            "[-5.0643938]\n",
            "[-5.09339794]\n",
            "[-5.12239543]\n",
            "[-5.15138635]\n",
            "[-5.18037078]\n",
            "[-5.20934881]\n",
            "[-5.2383205]\n",
            "[-5.26728593]\n",
            "[-5.29624518]\n",
            "[-5.32519832]\n",
            "[-5.35414542]\n",
            "[-5.38308655]\n",
            "[-5.41202178]\n",
            "[-5.44095119]\n",
            "[-5.46987482]\n",
            "[-5.49879276]\n",
            "[-5.52770506]\n",
            "[-5.5566118]\n",
            "[-5.58551302]\n",
            "[-5.6144088]\n",
            "[-5.64329919]\n",
            "[-5.67218426]\n",
            "[-5.70106406]\n",
            "[-5.72993865]\n",
            "[-5.75880809]\n",
            "[-5.78767243]\n",
            "[-5.81653172]\n",
            "[-5.84538603]\n",
            "[-5.87423541]\n",
            "[-5.90307991]\n",
            "[-5.93191957]\n",
            "[-5.96075446]\n",
            "[-5.98958462]\n",
            "[-6.0184101]\n",
            "[-6.04723095]\n",
            "[-6.07604723]\n",
            "[-6.10485896]\n",
            "[-6.13366622]\n",
            "[-6.16246903]\n",
            "[-6.19126745]\n",
            "[-6.22006151]\n",
            "[-6.24885127]\n",
            "[-6.27763678]\n",
            "[-6.30641806]\n",
            "[-6.33519516]\n",
            "[-6.36396813]\n",
            "[-6.39273701]\n",
            "[-6.42150184]\n",
            "[-6.45026265]\n",
            "[-6.4790195]\n",
            "[-6.50777241]\n",
            "[-6.53652143]\n",
            "[-6.56526659]\n",
            "[-6.59400793]\n",
            "[-6.62274549]\n",
            "[-6.65147931]\n",
            "[-6.68020942]\n",
            "[-6.70893586]\n",
            "[-6.73765866]\n",
            "[-6.76637786]\n",
            "[-6.79509349]\n",
            "[-6.82380559]\n",
            "[-6.85251419]\n",
            "[-6.88121932]\n",
            "[-6.90992102]\n",
            "[-6.93861932]\n",
            "[-6.96731425]\n",
            "[-6.99600584]\n",
            "[-7.02469412]\n",
            "[-7.05337913]\n",
            "[-7.08206089]\n",
            "[-7.11073944]\n",
            "[-7.13941481]\n",
            "[-7.16808701]\n",
            "[-7.19675609]\n",
            "[-7.22542207]\n",
            "[-7.25408498]\n",
            "[-7.28274485]\n",
            "[-7.31140171]\n",
            "[-7.34005558]\n",
            "[-7.36870648]\n",
            "[-7.39735446]\n",
            "[-7.42599953]\n",
            "[-7.45464171]\n",
            "[-7.48328104]\n",
            "[-7.51191755]\n",
            "[-7.54055124]\n",
            "[-7.56918216]\n",
            "[-7.59781033]\n",
            "[-7.62643576]\n",
            "[-7.65505849]\n",
            "[-7.68367853]\n",
            "[-7.71229592]\n",
            "[-7.74091067]\n",
            "[-7.7695228]\n",
            "[-7.79813235]\n",
            "[-7.82673933]\n",
            "[-7.85534377]\n",
            "[-7.88394568]\n",
            "[-7.91254509]\n",
            "[-7.94114202]\n",
            "[-7.96973649]\n",
            "[-7.99832853]\n",
            "[-8.02691815]\n",
            "[-8.05550537]\n",
            "[-8.08409022]\n",
            "[-8.11267271]\n",
            "[-8.14125286]\n",
            "[-8.1698307]\n",
            "[-8.19840625]\n",
            "[-8.22697951]\n",
            "[-8.25555052]\n",
            "[-8.28411929]\n",
            "[-8.31268584]\n",
            "[-8.34125019]\n",
            "[-8.36981235]\n",
            "[-8.39837235]\n",
            "[-8.4269302]\n",
            "[-8.45548592]\n",
            "[-8.48403953]\n",
            "[-8.51259105]\n",
            "[-8.54114048]\n",
            "[-8.56968786]\n",
            "[-8.59823319]\n",
            "[-8.6267765]\n",
            "[-8.65531779]\n",
            "[-8.68385709]\n",
            "[-8.71239441]\n",
            "[-8.74092977]\n",
            "[-8.76946318]\n",
            "[-8.79799466]\n",
            "[-8.82652422]\n",
            "[-8.85505189]\n",
            "[-8.88357767]\n",
            "[-8.91210158]\n",
            "[-8.94062363]\n",
            "[-8.96914384]\n",
            "[-8.99766223]\n",
            "[-9.02617881]\n",
            "[-9.05469359]\n",
            "[-9.08320658]\n",
            "[-9.11171781]\n",
            "[-9.14022728]\n",
            "[-9.16873501]\n",
            "[-9.19724101]\n",
            "[-9.2257453]\n",
            "[-9.25424788]\n",
            "[-9.28274878]\n",
            "[-9.311248]\n",
            "[-9.33974556]\n",
            "[-9.36824147]\n",
            "[-9.39673574]\n",
            "[-9.42522839]\n",
            "[-9.45371942]\n",
            "[-9.48220886]\n",
            "[-9.51069671]\n",
            "[-9.53918298]\n",
            "[-9.56766769]\n",
            "[-9.59615085]\n",
            "[-9.62463246]\n",
            "[-9.65311255]\n",
            "[-9.68159113]\n",
            "[-9.71006819]\n",
            "[-9.73854376]\n",
            "[-9.76701785]\n",
            "[-9.79549047]\n",
            "[-9.82396162]\n",
            "[-9.85243133]\n",
            "[-9.88089959]\n",
            "[-9.90936642]\n",
            "[-9.93783184]\n",
            "[-9.96629585]\n",
            "[-9.99475846]\n",
            "[-10.02321968]\n",
            "[-10.05167953]\n",
            "[-10.080138]\n",
            "[-10.10859512]\n",
            "[-10.13705089]\n",
            "[-10.16550533]\n",
            "[-10.19395843]\n",
            "[-10.22241022]\n",
            "[-10.25086069]\n",
            "[-10.27930987]\n",
            "[-10.30775776]\n",
            "[-10.33620436]\n",
            "[-10.36464969]\n",
            "[-10.39309376]\n",
            "[-10.42153657]\n",
            "[-10.44997814]\n",
            "[-10.47841848]\n",
            "[-10.50685758]\n",
            "[-10.53529547]\n",
            "[-10.56373214]\n",
            "[-10.59216761]\n",
            "[-10.62060189]\n",
            "[-10.64903498]\n",
            "[-10.6774669]\n",
            "[-10.70589764]\n",
            "[-10.73432723]\n",
            "[-10.76275566]\n",
            "[-10.79118295]\n",
            "[-10.8196091]\n",
            "[-10.84803412]\n",
            "[-10.87645802]\n",
            "[-10.90488081]\n",
            "[-10.93330249]\n",
            "[-10.96172307]\n",
            "[-10.99014256]\n",
            "[-11.01856096]\n",
            "[-11.04697829]\n",
            "[-11.07539456]\n",
            "[-11.10380975]\n",
            "[-11.1322239]\n",
            "[-11.16063699]\n",
            "[-11.18904905]\n",
            "[-11.21746007]\n",
            "[-11.24587007]\n",
            "[-11.27427904]\n",
            "[-11.302687]\n",
            "[-11.33109396]\n",
            "[-11.35949992]\n",
            "[-11.38790488]\n",
            "[-11.41630886]\n",
            "[-11.44471185]\n",
            "[-11.47311388]\n",
            "[-11.50151493]\n",
            "[-11.52991503]\n",
            "[-11.55831417]\n",
            "[-11.58671236]\n",
            "[-11.61510961]\n",
            "[-11.64350592]\n",
            "[-11.6719013]\n",
            "[-11.70029576]\n",
            "[-11.72868931]\n",
            "[-11.75708194]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBz-vuy6USQX"
      },
      "source": [
        "Again, plot and check to see if the model is converging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI7-ve1lUSQY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "81109876-54e9-49ee-8cc7-78262d450997"
      },
      "source": [
        "plt.plot(list(range(0, len(J_history))), J_history, '-b')  \n",
        "plt.xlabel('Number of iterations')\n",
        "plt.ylabel('Cost J')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ7vClqtUSQf"
      },
      "source": [
        "## Decision Boundary\n",
        "In addition to checking convergence graph and accuracy, we can also plot out the decision boundary to see what does the model actually learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDhTGlzFUSQf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "8dec97f9-c0dd-4882-fefe-562cdba43398"
      },
      "source": [
        "# Plot the feature according to their class label.\n",
        "# Note that we exclude column 0, which is the colunm we padded with one in the previous block.\n",
        "plt.plot(X[np.where(y==1), 1], X[np.where(y==1), 2], 'rx')\n",
        "plt.plot(X[np.where(y==-1), 1], X[np.where(y==-1), 2], 'bo')\n",
        "\n",
        "#####################################################################\n",
        "# Instructions: Plot out the decision boundary.                     #\n",
        "# Hint: To plot the boundary, which is a straight line in our case, #\n",
        "#       you need to find the two ends of the line, and plot it with #\n",
        "#       plt.plot(). Note that the decision boundary is the line that#\n",
        "#       y = 0.                                                      # \n",
        "#####################################################################\n",
        "plot_x = [np.min(X[:,1]), np.max(X[:,2])]\n",
        "# I found the decision boundary in this way mentioned in Piazza:\n",
        "# Set the DB equation equal to theta_0 + theta_1 * x_1 + theta_2 * x_2\n",
        "# Thus, DB(X) = theta_0 + theta_1 * x_1 + theta_2 * x_2\n",
        "# We assume DB(X) = 0\n",
        "# We get the equation of the form x_2 = f(x_1) and plot it.\n",
        "plot_y = (-1./theta[2]) * ((theta[1] * (plot_x) + theta[0]))\n",
        "plt.plot(plot_x, plot_y, label='Decision boundary')\n",
        "pass\n",
        "#####################################################################\n",
        "#                       END OF YOUR CODE                            #\n",
        "#####################################################################\n",
        "\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shWKz8-hUSQi"
      },
      "source": [
        "# Section 2. Regularization [30 pts]:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6u2mu0-USQi"
      },
      "source": [
        "In this section, you need to incorporate L2 regularization into your logistic regression. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs9SvcGsUSQj"
      },
      "source": [
        "## L2 Regularization\n",
        "Overfitting is a notorious problem in the world of machine learning. One simple way to counter this issue is to put constraints on your model weights $\\theta$, as we have discussed in class. In this section, you need to modify the the objective function to impose L2 regularization on the logistic regression:\n",
        "\\begin{equation*}\n",
        "    J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^m\\log{\\left(h_{\\theta}(y^{(i)}x^{(i)})\\right)} + \\lambda\\vert\\vert\\theta\\vert\\vert_2^2\n",
        "\\end{equation*}\n",
        "Derive the gradient for this new objective to incorporate it into your logistic regression model.\n",
        "\n",
        "To make things much structural, we now put everything together into a class. Please use the class template below to implement your logistic regression. Note that you can add your own class methods if needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R56endnUSQp"
      },
      "source": [
        "class LogisticRegression(object):\n",
        "    \n",
        "    def __init__(self, alpha=0.1, lamb=0.1, regularization=None):\n",
        "        # setting the class attribute.\n",
        "        self.alpha = alpha                   # Set up your learning rate alpha.\n",
        "        self.lamb = lamb                     # Strength of regularization.\n",
        "        self.regularization = regularization \n",
        "        assert regularization == 'l2' or regularization == None # we only consider these two cases\n",
        "\n",
        "    def sigmoid(z):\n",
        "        g = 1 / (1 + np.exp(-z))\n",
        "        return g\n",
        "\n",
        "    def _compute_cost(self, X, y):\n",
        "        #####################################################################\n",
        "        # Instructions: Compute the cost function here.                     #\n",
        "        #               You need to handle both the cases with, and without #\n",
        "        #               regularization here.                                #\n",
        "        #####################################################################\n",
        "        if (regularization == None):\n",
        "          J=compute_cost(X,y,self.theta)  \n",
        "        else:  \n",
        "          h = sigmoid(np.dot(X,theta))\n",
        "          cost = (-y * np.log(h)) - ((1-y)*np.log(1-h))\n",
        "          l2 = np.sum(np.power(theta,2))\n",
        "          J = 1/m * sum(cost) + lamb * np.power(l2 , 2)\n",
        "        pass\n",
        "        #####################################################################\n",
        "        #                       END OF YOUR CODE                            #\n",
        "        #####################################################################\n",
        "        return J\n",
        "        \n",
        "    def _compute_gradient(self, X, y):\n",
        "        #####################################################################\n",
        "        # Instructions: Compute the gradient here.                          #\n",
        "        #               You need to handle both the cases with, and without #\n",
        "        #               regularization here.                                #\n",
        "        #####################################################################\n",
        "        if (regularization == None):\n",
        "            gradient_=compute_gradient(X, y, theta)  \n",
        "        else: \n",
        "            h2 = sigmoid(np.dot(X,theta))\n",
        "            gradient_ = 1/m * (np.dot(X.transpose(), (h2-y)))\n",
        "            regularization = (self.lamb / m) * self.theta\n",
        "            gradient= gradi + regularization\n",
        "        pass\n",
        "        #####################################################################\n",
        "        #                       END OF YOUR CODE                            #\n",
        "        #####################################################################\n",
        "        return gradient\n",
        "\n",
        "    def fit(self, X, y, num_iter=5):\n",
        "        self.theta = np.zeros((X.shape[1], 1))\n",
        "        m = len(y)\n",
        "        J_history = []\n",
        "        #####################################################################\n",
        "        # Instructions: Run the gradient decsent here.                      #\n",
        "        #####################################################################\n",
        "        for i in range(num_iters):\n",
        "            grad= self._compute_gradient(X, y) \n",
        "            theta = theta-alpha*grad\n",
        "            J = self._compute_cost(X, y)\n",
        "            J_history  = J_history.append(J)\n",
        "        pass\n",
        "        #####################################################################\n",
        "        #                       END OF YOUR CODE                            #\n",
        "        #####################################################################\n",
        "        return J_history\n",
        "    \n",
        "    def predict(self, X):\n",
        "        #####################################################################\n",
        "        # Instructions: Use your hypothese to make predictions.             #\n",
        "        #####################################################################\n",
        "        pass\n",
        "        #####################################################################\n",
        "        #                       END OF YOUR CODE                            #\n",
        "        #####################################################################\n",
        "        return y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvOuwb--USQr"
      },
      "source": [
        "Load the wine datasets, in which $x_j\\in\\mathbb{R}^{12}$ is different attribute for alcohol, and $y\\in\\{-1,1\\}$ is that class label (red or white wine)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcJhvSKZUSQs"
      },
      "source": [
        "# Load dataset\n",
        "import numpy as np\n",
        "X_train = np.loadtxt(os.path.join(customized_path_to_your_homework, 'data/wine_train_X.txt'))\n",
        "y_train = np.loadtxt(os.path.join(customized_path_to_your_homework, 'data/wine_train_y.txt')).reshape(-1, 1)\n",
        "X_test = np.loadtxt(os.path.join(customized_path_to_your_homework, 'data/wine_test_X.txt'))\n",
        "y_test = np.loadtxt(os.path.join(customized_path_to_your_homework, 'data/wine_test_y.txt')).reshape(-1, 1)\n",
        "\n",
        "\n",
        "X_train = np.concatenate((np.ones((X_train.shape[0], 1)), X_train), axis=1)\n",
        "X_test = np.concatenate((np.ones((X_test.shape[0], 1)), X_test), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrVpJHEaUSQx"
      },
      "source": [
        "Now, let's train two different logistic regression models: one with, and one without regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L4_u_m5USQy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "be2a0bf5-e86e-4b5f-bc21-bd1518cf8c16"
      },
      "source": [
        "log_reg = LogisticRegression(alpha=0.1) # Without regularization\n",
        "log_reg_l2 = LogisticRegression(alpha=0.1, lamb=1.0, regularization='l2') # Without regularization\n",
        "\n",
        "J_history = log_reg.fit(X_train, y_train, num_iter=500)\n",
        "J_history_l2 = log_reg_l2.fit(X_train, y_train, num_iter=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-25611e0c9423>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlog_reg_l2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Without regularization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mJ_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mJ_history_l2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_reg_l2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-96-655efb886e61>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, num_iter)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m#####################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mgrad\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mJ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-96-655efb886e61>\u001b[0m in \u001b[0;36m_compute_gradient\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#               regularization here.                                #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#####################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mregularization\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mgradient_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'regularization' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLoIsIXCAb5V"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUcN2QkLAcfE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LbnavioUSQ2"
      },
      "source": [
        "Next, we evaluate the accuracy for each method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUPmeq4BUSQ3"
      },
      "source": [
        "def evaluate_accuracy(X, y, model):\n",
        "    y_pred = model.predict(X)\n",
        "    y_pred[y_pred > 0.5] = 1\n",
        "    y_pred[y_pred <= 0.5] = -1\n",
        "    return np.mean(y_pred == y)\n",
        "\n",
        "print(\"Accuracy on training set: \", evaluate_accuracy(X_train, y_train, log_reg))\n",
        "print(\"Accuracy on testing set: \", evaluate_accuracy(X_test, y_test, log_reg))\n",
        "print(\"Accuracy w/ L2 training set: \", evaluate_accuracy(X_train, y_train, log_reg_l2))\n",
        "print(\"Accuracy w/ L2 testing set: \", evaluate_accuracy(X_test, y_test, log_reg_l2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHzJ9-fiUSQ6"
      },
      "source": [
        "To see the effect of regularization on $\\theta$, we can plot out each $\\theta_j$ under different $\\lambda$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruUGI7ZbUSQ6"
      },
      "source": [
        "def plot_theta(theta, lamb):\n",
        "    \"\"\"\n",
        "    Helper function for plotting out the value of theta with respect to different lambda.\n",
        "    theta  (list): list of theta under different lambda.\n",
        "    lambda (list): list of lambda values you tried.\n",
        "    \"\"\"\n",
        "    plt.hlines(y=0, xmin=0, xmax=np.max(lamb), color='red', linewidth = 2, linestyle = '--')\n",
        "    for i in range(theta.shape[1]):\n",
        "        plt.plot(lamb, theta[:,i])\n",
        "    plt.ylabel('theta')\n",
        "    plt.xlabel('lambda')\n",
        "    plt.xscale('log')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdz5Fu2ecDRw"
      },
      "source": [
        "## Plot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrXZdXtLUSQ_"
      },
      "source": [
        "lamb = [0.1, 1, 10, 100, 1000]\n",
        "theta = []\n",
        "\n",
        "#####################################################################\n",
        "# Instructions: For each value in lamb, try a model for it, and     #\n",
        "#               append the trained weights into the theta           #\n",
        "#####################################################################\n",
        "for i in lamb:\n",
        "    log_reg_l2 = LogisticRegression(alpha=0.1, lamb=i, regularization='l2')\n",
        "    log_reg_l2.fit(X_train, y_train)\n",
        "    theta.append(log_reg_l2.theta)\n",
        "pass\n",
        "#####################################################################\n",
        "#                       END OF YOUR CODE                            #\n",
        "#####################################################################\n",
        "\n",
        "plot_theta(np.array(theta), lamb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dNrM5d_s72A"
      },
      "source": [
        "# Save as PDF\n",
        "Please use the following codes to save your notebook as a PDF file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrCQ6jY2USRB"
      },
      "source": [
        "#Run below two lines (in google colab), installation steps to get .pdf of the notebook\n",
        "\n",
        "!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n",
        "!pip install pypandoc\n",
        "\n",
        "#After installation, comment above two lines and run again to remove installation comments from the notebook."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEg7wyn_s90U"
      },
      "source": [
        " Find path to your notebook file in drive and enter in below line\n",
        "!jupyter nbconvert --to PDF \"/content/gdrive/MyDrive/ECE 5424 ML/homework_spring/HW2/ECE_CS_5424_Assignment_2.ipynb\"\n",
        "#Example: \"/content/gdrive/MyDrive/ECE 5424 ML/homework_spring/HW2/ECE_CS_5424_Assignment_2.ipynb\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}